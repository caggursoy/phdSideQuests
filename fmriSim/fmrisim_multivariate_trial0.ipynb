{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from pathlib import Path\n",
    "from brainiak.utils import fmrisim\n",
    "import nibabel\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.spatial.distance as sp_distance\n",
    "import sklearn.manifold as manifold\n",
    "import scipy.stats as stats\n",
    "import sklearn.model_selection\n",
    "import sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = str(Path().absolute())\n",
    "nii = nibabel.load(home + '/Corr_MVPA/Participant_01_loc_run01.nii') # 4 dimensional data that is readable by nibabel\n",
    "volume = nii.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 27, 294)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcf6b40c790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = volume.shape  # What is the size of the volume\n",
    "dimsize = nii.header.get_zooms()  # Get voxel dimensions from the nifti header\n",
    "tr = dimsize[3]\n",
    "if tr > 100:  # If high then these values are likely in ms\n",
    "    tr /= 1000\n",
    "print(dim)\n",
    "vol3d = nibabel.four_to_three(nii) # added, to print the brain image from dataset\n",
    "for pp in vol3d:\n",
    "    volDat = pp.get_fdata()\n",
    "plt.imshow(volDat[:,:,15], cmap = \"gray\", origin = \"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask, template = fmrisim.mask_brain(volume=volume, \n",
    "                                    mask_self=True,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/klips/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/base/model.py:492: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4b65ea7528f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mtemplate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                 \u001b[0mnoise_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                 )\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/brainiak/utils/fmrisim.py\u001b[0m in \u001b[0;36mcalc_noise\u001b[0;34m(volume, mask, template, noise_dict)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0;31m# Calculate the temporal variability of the volume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m     noise_dict['auto_reg_rho'], noise_dict['ma_rho'] = _calc_ARMA_noise(\n\u001b[0;32m-> 1340\u001b[0;31m         volume, mask)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;31m# Set it such that all of the temporal variability will be accounted for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/brainiak/utils/fmrisim.py\u001b[0m in \u001b[0;36m_calc_ARMA_noise\u001b[0;34m(volume, mask, auto_reg_order, ma_order, sample_num)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mARMA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemeaned_timecourse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mauto_reg_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma_order\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             \u001b[0mmodel_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, trend, method, transparams, solver, maxiter, full_output, disp, callback, start_ar_lags, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# estimate starting parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             start_params = self._fit_start_params((k_ar, k_ma, k), method,\n\u001b[0;32m--> 938\u001b[0;31m                                                   start_ar_lags)\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparams\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# transform initial parameters to ensure invertibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m_fit_start_params\u001b[0;34m(self, order, method, start_ar_lags)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m#start_params = [.1]*(k_ar+k_ma+k_exog) # different one for k?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_start_params_hr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_ar_lags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invtransparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/tsa/arima_model.py\u001b[0m in \u001b[0;36m_fit_start_params_hr\u001b[0;34m(self, order, start_ar_lags)\u001b[0m\n\u001b[1;32m    491\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmaxlag\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                         \u001b[0mmaxlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnobs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                     \u001b[0marmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mstart_ar_lags\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/tsa/ar_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, maxlag, method, ic, trend, transparams, start_params, solver, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mic\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'aic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hqic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't-stat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ic option %s not understood\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0mk_ar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_ar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_ar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_ar\u001b[0m  \u001b[0;31m# change to what was chosen by ic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/tsa/ar_model.py\u001b[0m in \u001b[0;36mselect_order\u001b[0;34m(self, maxlag, ic, trend, method)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 fit = AR(endog_tmp).fit(maxlag=lag, method=method,\n\u001b[1;32m    431\u001b[0m                                         \u001b[0mfull_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                                         maxiter=100, disp=0)\n\u001b[0m\u001b[1;32m    433\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mbestic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/tsa/ar_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, maxlag, method, ic, trend, transparams, start_params, solver, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cmle\"\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0;31m# do OLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0marfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnobs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk_ar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     hasattr(self, 'rank')):\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv_wexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingular_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpinv_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 self.normalized_cov_params = np.dot(\n\u001b[1;32m    292\u001b[0m                     self.pinv_wexog, np.transpose(self.pinv_wexog))\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/statsmodels/tools/tools.py\u001b[0m in \u001b[0;36mpinv_extended\u001b[0;34m(X, rcond)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0ms_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/venv/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calculate the noise parameters from the data. Set it up to be matched.\n",
    "noise_dict = {'voxel_size': [dimsize[0], dimsize[1], dimsize[2]], 'matched': 1}\n",
    "noise_dict = fmrisim.calc_noise(volume=volume,\n",
    "                                mask=mask,\n",
    "                                template=template,\n",
    "                                noise_dict=noise_dict,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Noise parameters of the data were estimated as follows:')\n",
    "print('SNR: ' + str(noise_dict['snr']))\n",
    "print('SFNR: ' + str(noise_dict['sfnr']))\n",
    "print('FWHM: ' + str(noise_dict['fwhm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the noise given the parameters\n",
    "noise = fmrisim.generate_noise(dimensions=dim[0:3],\n",
    "                               tr_duration=int(tr),\n",
    "                               stimfunction_tr=[0] * dim[3], \n",
    "                               mask=mask,\n",
    "                               template=template,\n",
    "                               noise_dict=noise_dict,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a slice through the noise brain\n",
    "plt.figure()\n",
    "plt.imshow(noise[:, :, int(dim[2] / 2), 0], cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial noise\n",
    "low_spatial = fmrisim._generate_noise_spatial(dim[0:3],\n",
    "                                              fwhm=4.0,\n",
    "                                              )\n",
    "\n",
    "high_spatial = fmrisim._generate_noise_spatial(dim[0:3],\n",
    "                                               fwhm=1.0,\n",
    "                                               )\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('FWHM = 4.0')\n",
    "plt.imshow(low_spatial[:, :, 12])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('FWHM = 1.0')\n",
    "plt.imshow(high_spatial[:, :, 12])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the different types of noise\n",
    "total_time = 500\n",
    "timepoints = list(range(0, total_time, int(tr)))\n",
    "\n",
    "drift = fmrisim._generate_noise_temporal_drift(total_time,\n",
    "                                               int(tr),\n",
    "                                               )\n",
    "\n",
    "mini_dim = np.array([2, 2, 2])\n",
    "autoreg = fmrisim._generate_noise_temporal_autoregression(timepoints,\n",
    "                                                          noise_dict,\n",
    "                                                          mini_dim,\n",
    "                                                          np.ones(mini_dim)\n",
    "                                                          )\n",
    "            \n",
    "phys = fmrisim._generate_noise_temporal_phys(timepoints,\n",
    "                                            )\n",
    "\n",
    "stimfunc = np.zeros((int(total_time / tr), 1))\n",
    "stimfunc[np.random.randint(0, int(total_time / tr), 50)] = 1\n",
    "task = fmrisim._generate_noise_temporal_task(stimfunc,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the different noise types\n",
    "plt.figure()\n",
    "plt.title('Noise types')\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(drift)\n",
    "plt.axis('off')\n",
    "plt.xlabel('Drift')\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(autoreg[0, 0, 0, :])\n",
    "plt.axis('off')\n",
    "plt.xlabel('Autoregression')\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(phys)\n",
    "plt.axis('off')\n",
    "plt.xlabel('Physiological')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(task)\n",
    "plt.axis('off')\n",
    "plt.xlabel('Task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilate the mask so as to only take voxels far from the brain (performed in calc_noise)\n",
    "mask_dilated = ndimage.morphology.binary_dilation(mask, iterations=10)\n",
    "\n",
    "# Remove all non brain voxels\n",
    "system_all = volume[mask_dilated == 0]  # Pull out all the non brain voxels in the first TR\n",
    "system_baseline = volume - (template.reshape(dim[0], dim[1], dim[2], 1) * noise_dict['max_activity'])  # Subtract the baseline before masking\n",
    "system_baseline = system_baseline[mask_dilated == 0]\n",
    "\n",
    "# Plot the distribution of voxels\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(system_all[:,0].flatten(),100)\n",
    "plt.title('Non-brain distribution')\n",
    "plt.xlabel('Activity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Identify a subset of voxels to plot\n",
    "idxs = list(range(system_all.shape[0]))\n",
    "np.random.shuffle(idxs)\n",
    "\n",
    "temporal = system_all[idxs[:100], :100]\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(temporal)\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.ylabel('voxel ID')\n",
    "plt.xlabel('time')\n",
    "plt.title('Voxel x time')\n",
    "plt.colorbar(orientation = 'horizontal')\n",
    "\n",
    "# Plot the difference\n",
    "ax=plt.subplot(1, 3, 3)\n",
    "plt.hist(system_baseline[:,0].flatten(),100)\n",
    "ax.yaxis.tick_right()\n",
    "ax.yaxis.set_label_position(\"right\")\n",
    "plt.title('Demeaned non-brain distribution')\n",
    "plt.xlabel('Activity difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the noise parameters for the simulated noise\n",
    "noise_dict_sim = {'voxel_size': [dimsize[0], dimsize[1], dimsize[2]], 'matched': 1}\n",
    "noise_dict_sim = fmrisim.calc_noise(volume=noise,\n",
    "                                    mask=mask,\n",
    "                                    template=template,\n",
    "                                    noise_dict=noise_dict_sim,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Compare noise parameters for the real and simulated noise:')\n",
    "print('SNR: %0.2f vs %0.2f' % (noise_dict['snr'], noise_dict_sim['snr']))\n",
    "print('SFNR: %0.2f vs %0.2f' % (noise_dict['sfnr'], noise_dict_sim['sfnr']))\n",
    "print('FWHM: %0.2f vs %0.2f' % (noise_dict['fwhm'], noise_dict_sim['fwhm']))\n",
    "print('AR: %0.2f vs %0.2f' % (noise_dict['auto_reg_rho'][0], noise_dict_sim['auto_reg_rho'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the region of activity where signal will appear\n",
    "coordinates = np.array([[21, 21, 21]])  # Where in the brain is the signal\n",
    "feature_size = 3  # How big, in voxels, is the size of the ROI\n",
    "signal_volume = fmrisim.generate_signal(dimensions=dim[0:3],\n",
    "                                        feature_type=['cube'],\n",
    "                                        feature_coordinates=coordinates,\n",
    "                                        feature_size=[feature_size],\n",
    "                                        signal_magnitude=[1],\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(signal_volume[:, :, 21], cmap=plt.cm.gray) # set slice number here to observe the right one\n",
    "plt.imshow(mask[:, :, 21], cmap=plt.cm.gray, alpha=.5)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern for each voxel in our signal ROI\n",
    "voxels = feature_size ** 3\n",
    "\n",
    "# Pull the conical voxel activity from a uniform distribution\n",
    "pattern_A = np.random.rand(voxels).reshape((voxels, 1))  \n",
    "pattern_B = np.random.rand(voxels).reshape((voxels, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pattern of activity for each condition\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(pattern_A)\n",
    "plt.ylabel('Voxels')\n",
    "plt.tick_params(which='both', left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "plt.xlabel('Condition A')\n",
    "plt.colorbar(orientation = 'horizontal')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(pattern_B)\n",
    "plt.tick_params(which='both', left=False, labelleft=False, bottom=False, labelbottom=False)\n",
    "plt.xlabel('Condition B')\n",
    "plt.colorbar(orientation = 'horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up stimulus event time course parameters\n",
    "event_duration = 2  # How long is each event\n",
    "isi = 7  # What is the time between each event\n",
    "burn_in = 1  # How long before the first event\n",
    "\n",
    "total_time = int(dim[3] * tr) + burn_in  # How long is the total event time course\n",
    "events = int((total_time - ((event_duration + isi) * 2))  / ((event_duration + isi) * 2)) * 2  # How many events are there?\n",
    "onsets_all = np.linspace(burn_in, events * (event_duration + isi), events)  # Space the events out\n",
    "np.random.shuffle(onsets_all)  # Shuffle their order\n",
    "onsets_A = onsets_all[:int(events / 2)]  # Assign the first half of shuffled events to condition A\n",
    "onsets_B = onsets_all[int(events / 2):]  # Assign the second half of shuffled events to condition B\n",
    "temporal_res = 10.0 # How many timepoints per second of the stim function are to be generated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time course of events \n",
    "stimfunc_A = fmrisim.generate_stimfunction(onsets=onsets_A,\n",
    "                                           event_durations=[event_duration],\n",
    "                                           total_time=total_time,\n",
    "                                           temporal_resolution=temporal_res,\n",
    "                                           )\n",
    "\n",
    "stimfunc_B = fmrisim.generate_stimfunction(onsets=onsets_B,\n",
    "                                           event_durations=[event_duration],\n",
    "                                           total_time=total_time,\n",
    "                                           temporal_resolution=temporal_res,\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmrisim.export_epoch_file(stimfunction=[np.hstack((stimfunc_A, stimfunc_B))],\n",
    "                          filename=home + '/epoch_file.npy',\n",
    "                          tr_duration=tr,\n",
    "                          temporal_resolution=temporal_res,\n",
    "                          )\n",
    "\n",
    "fmrisim.export_3_column(stimfunction=stimfunc_A,\n",
    "                        filename=home + '/Condition_A.txt',\n",
    "                        temporal_resolution=temporal_res,\n",
    "                        )\n",
    "\n",
    "fmrisim.export_3_column(stimfunction=stimfunc_B,\n",
    "                        filename=home + '/Condition_B.txt',\n",
    "                        temporal_resolution=temporal_res,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply each pattern by each voxel time course\n",
    "weights_A = np.matlib.repmat(stimfunc_A, 1, voxels).transpose() * pattern_A\n",
    "weights_B = np.matlib.repmat(stimfunc_B, 1, voxels).transpose() * pattern_B\n",
    "\n",
    "# Sum these time courses together\n",
    "stimfunc_weighted = weights_A + weights_B\n",
    "stimfunc_weighted = stimfunc_weighted.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(stimfunc_weighted[:, 0])\n",
    "plt.title('Example voxel response time course')\n",
    "plt.xlabel('Upsampled time course')\n",
    "plt.ylabel('Response size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_func = fmrisim.convolve_hrf(stimfunction=stimfunc_weighted,\n",
    "                                   tr_duration=tr,\n",
    "                                   temporal_resolution=temporal_res,\n",
    "                                   scale_function=1,\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be plotted\n",
    "response = signal_func[0:100,0] * 2\n",
    "downsample_A = stimfunc_A[0:int(100*temporal_res * tr):int(temporal_res * tr), 0]\n",
    "downsample_B = stimfunc_B[0:int(100*temporal_res * tr):int(temporal_res * tr), 0]\n",
    "\n",
    "# Display signal\n",
    "plt.figure()\n",
    "plt.title('Example event time course and voxel response')\n",
    "Event_A = plt.plot(downsample_A, 'r', label='Event_A')\n",
    "Event_B = plt.plot(downsample_B, 'g', label='Event_B')\n",
    "Response = plt.plot(response, 'b', label='Response')\n",
    "plt.legend(loc=1)\n",
    "plt.yticks([],'')\n",
    "plt.xlabel('nth TR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the signal appropriate scaled\n",
    "signal_func_scaled = fmrisim.compute_signal_change(signal_func,\n",
    "                                                  noise_func,\n",
    "                                                  noise_dict,\n",
    "                                                  magnitude=signal_magnitude,\n",
    "                                                  method=signal_method,\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters for signal\n",
    "signal_method = 'CNR_Amp/Noise-SD'\n",
    "signal_magnitude = [0.5]\n",
    "\n",
    "# Where in the brain are there stimulus evoked voxels\n",
    "signal_idxs = np.where(signal_volume == 1)\n",
    "\n",
    "# Pull out the voxels corresponding to the noise volume\n",
    "noise_func = noise[signal_idxs[0], signal_idxs[1], signal_idxs[2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = fmrisim.apply_signal(signal_func_scaled,\n",
    "                              signal_volume,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = signal + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrf_lag = 4  # Assumed time from stimulus onset to HRF peak\n",
    "\n",
    "# Get the lower and upper bounds of the ROI\n",
    "lb = (coordinates - ((feature_size - 1) / 2)).astype('int')[0]\n",
    "ub = (coordinates + ((feature_size - 1) / 2) + 1).astype('int')[0]\n",
    "\n",
    "# Pull out voxels in the ROI for the specified timepoints\n",
    "trials_A = brain[lb[0]:ub[0], lb[1]:ub[1], lb[2]:ub[2], ((onsets_A + hrf_lag) / tr).astype('int')]\n",
    "trials_B = brain[lb[0]:ub[0], lb[1]:ub[1], lb[2]:ub[2], ((onsets_B + hrf_lag) / tr).astype('int')]\n",
    "\n",
    "# Reshape data for easy handling\n",
    "trials_A = trials_A.reshape((voxels, trials_A.shape[3]))\n",
    "trials_B = trials_B.reshape((voxels, trials_B.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pattern of activity for our signal voxels at each timepoint\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(trials_A)\n",
    "plt.colorbar(orientation = 'horizontal')\n",
    "plt.ylabel('Voxels')\n",
    "plt.xlabel('Trials A')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(trials_B)\n",
    "plt.colorbar(orientation = 'horizontal')\n",
    "plt.xlabel('Trials B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance matrix between trial types\n",
    "distance_matrix = sp_distance.squareform(sp_distance.pdist(np.vstack([trials_A.transpose(), trials_B.transpose()])))\n",
    "\n",
    "mds = manifold.MDS(n_components=2, dissimilarity='precomputed')  # Fit the mds object\n",
    "coords = mds.fit(distance_matrix).embedding_  # Find the mds coordinates\n",
    "\n",
    "# Plot the data\n",
    "plt.figure()\n",
    "plt.scatter(coords[:, 0], coords[:, 1], c=['red'] * trials_A.shape[1] + ['green'] * trials_B.shape[1])\n",
    "plt.axis('off')\n",
    "plt.title('Low Dimensional Representation of conditions A and B')\n",
    "plt.legend(['Cond A', 'Cond B'], loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_difference = (np.mean(trials_A,0) - np.mean(trials_B,0))\n",
    "ttest = stats.ttest_1samp(mean_difference, 0)\n",
    "\n",
    "print('Mean difference between condition A and B: %0.2f\\np value: %0.3f' % (mean_difference.mean(), ttest.pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the inputs to the SVM\n",
    "input_mat = np.vstack([trials_A.transpose(), trials_B.transpose()])\n",
    "input_labels = trials_A.shape[1] * [1] + trials_B.shape[1] * [0]\n",
    "\n",
    "# Set up the classifier\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    input_mat, input_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "clf = sklearn.svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "print('Classification accuracy between condition A and B: %0.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
